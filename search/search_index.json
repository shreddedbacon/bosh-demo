{
    "docs": [
        {
            "location": "/", 
            "text": "Prerequisites\n#\n\n\nYou need a few things installed\n\n\n\n\ndirenv\n\n\nBOSH additional dependencies\n\n\n\n\nUsing BUCC (BOSH, UAA, CredHub, and ConcourseCI)\n#\n\n\nFor this intro, we will use \nBUCC\n to set up a director easily.\n\n\nWe won't be using UAA, CredHub, or ConcourseCI in this introduction though.\n\n\nClone the BUCC repository, and allow direnv to run in here\n\n\ngit clone https://github.com/starkandwayne/bucc.git \n \ncd\n bucc/\ndirenv allow\n\n\n\n\n\nReference Material\n#\n\n\n\n\nBOSH Terminology\n\n\nBOSH Guides\n\n\nUltimate Guide to BOSH\n\n\nBOSH, UAA, CredHub, ConcourseCI\n\n\nStaticsite BOSH Release", 
            "title": "Getting Started"
        }, 
        {
            "location": "/#prerequisites", 
            "text": "You need a few things installed   direnv  BOSH additional dependencies", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/#using_bucc_bosh_uaa_credhub_and_concourseci", 
            "text": "For this intro, we will use  BUCC  to set up a director easily.  We won't be using UAA, CredHub, or ConcourseCI in this introduction though.  Clone the BUCC repository, and allow direnv to run in here  git clone https://github.com/starkandwayne/bucc.git    cd  bucc/\ndirenv allow", 
            "title": "Using BUCC (BOSH, UAA, CredHub, and ConcourseCI)"
        }, 
        {
            "location": "/#reference_material", 
            "text": "BOSH Terminology  BOSH Guides  Ultimate Guide to BOSH  BOSH, UAA, CredHub, ConcourseCI  Staticsite BOSH Release", 
            "title": "Reference Material"
        }, 
        {
            "location": "/director/", 
            "text": "Run \nbucc up\n to create a local director using virtualbox and BOSH lite\n\n\nThis can take some time to run while it downloads resources, starts a virtual machine in virtualbox and configures it as a director.\n\n\nbucc up\n\n\n\n\n\nOnce complete, you can get the rest of the tools if you need them (for this we aren't using them)\n\n\nbucc uaa\nbucc credhub\n\n\n\n\n\nThen run bosh env to display the director status\n\n\nbosh env\n\n\n\n\n\nWill produce the following output\n\n\nUsing environment \n192.168.50.6\n as client \nadmin\n\n\nName      bucc  \nUUID      fc8ae04d-165d-467c-9895-271dad173ec5  \nVersion   268.0.1 (00000000)  \nCPI       warden_cpi  \nFeatures  compiled_package_cache: disabled  \n          config_server: enabled  \n          dns: disabled  \n          snapshots: disabled  \nUser      admin\n\n\n\n\n\nAnd set up the host routes so your computer knows how to access the vms inside virtualbox\n\n\nbucc routes\n\n\n\n\n\n\n\nNote\n\n\nA lot of the next steps for this introduction will be run from within the bucc directory for easy clean up at the end.", 
            "title": "Build BOSH Director"
        }, 
        {
            "location": "/release/", 
            "text": "Init Release\n#\n\n\nFirst we need to create the release using the following command. It will create a directory called \nstaticsite-boshrelease\n and will set up a few directories and files for us to help get started.\n\n\nbosh init-release --dir\n=\nstaticsite-boshrelease\n\n\n\n\n\nThis will create some directories\n\n\nconfig/\njobs/\npackages/\nsrc/\n\n\n\n\n\n\n\nconfig contains files that describe our release and where our release stores its blobs externally.\n\n\njobs contains all the jobs that this release will have available to it, a job is a way to run a package or packages\n\n\npackages contains the packages that will be used in this release, it describes how to build/compile the packages\n\n\nsrc is where you can store sourcecode and files if you don't want to utilise an external blobstore\n\n\n\n\nCreate Source/Blob Files\n#\n\n\nNow that we have our release skeleton, we need to create the HTML that will deployed in this release, and all the resources we are using in our HTML (css/js).\n\n\nFirst we need to make a directory in the src folder to store our files that we need.\n\n\nmkdir src/static\n\n\n\n\n\nNow we need to get the bootstrap archive that contains the css/js we will be using and put it into the \nsrc/static\n directory too.\n\n\nwget -O src/static/bootstrap-4.1.3-dist.zip https://github.com/twbs/bootstrap/releases/download/v4.1.3/bootstrap-4.1.3-dist.zip\n\n\n\n\n\nAnd finally, generate the index.html file we will use.\n\n\ncat \n \nEOF\n \n src/static/index.html\n\nhtml\n\n  \nhead\n\n    \ntitle\nSamuel L Ipsum\n/title\n\n    \nlink \nrel\n=\nstylesheet\n \nhref\n=\n/css/bootstrap.min.css\n\n    \nscript \nsrc\n=\n/js/bootstrap.min.js\n/script\n\n  \n/head\n\n  \nbody\n\n    \nnav \nclass\n=\nnavbar navbar-expand-lg navbar-dark bg-dark\n\n      \nbutton \nclass\n=\nnavbar-toggler\n \ntype\n=\nbutton\n data-toggle\n=\ncollapse\n data-target\n=\n#navbarSupportedContent\n aria-controls\n=\nnavbarSupportedContent\n aria-expanded\n=\nfalse\n aria-label\n=\nToggle navigation\n\n        \nspan \nclass\n=\nnavbar-toggler-icon\n/span\n\n      \n/button\n\n      \ndiv \nclass\n=\ncollapse navbar-collapse\n \nid\n=\nnavbarSupportedContent\n\n        \nul \nclass\n=\nnavbar-nav mr-auto\n\n          \nli \nclass\n=\nnav-item active\n\n            \na \nclass\n=\nnav-link\n \nhref\n=\n/\nHome \nspan \nclass\n=\nsr-only\n(\ncurrent\n)\n/span\n/a\n\n          \n/li\n\n        \n/ul\n\n      \n/div\n\n    \n/nav\n\n    \ndiv \nclass\n=\ncontainer\n\n      \nh1\nSamuel L Ipsum\n/h1\n\n      \n!-- start slipsum code --\n\n      \nh2\nAre you ready \nfor\n the truth?\n/h2\n\n      Well, the way they make shows is, they make one show. That show\ns called a pilot. Then they show that show to the people who make shows, and on the strength of that one show they decide if they\nre going to make more shows. Some pilots get picked and become television programs. Some don\nt, become nothing. She starred in one of the ones that became nothing.\n\n\n      \nh2\nWe happy?\n/h2\n\n\n      Now that we know who you are, I know who I am. I\nm not a mistake! It all makes sense! In a comic, you know how you can tell who the arch-villain\ns going to be? He\ns the exact opposite of the hero. And most \ntimes\n they\nre friends, like you and me! I should\nve known way back when... You know why, David? Because of the kids. They called me Mr Glass.\n      \n!-- end slipsum code --\n\n    \n/div\n\n  \n/body\n\n\n/html\n\nEOF\n\n\n\n\n\nGenerate Package\n#\n\n\nNext up we need to create the package that will copy our static site into the right location on the deployed VM.\n\n\nFirst generate the package skeleton for our package that we will call \nstaticsite\n\n\nbosh generate-package staticsite\n\n\n\n\n\nNow we have a skeleton directory, it contains 2 files\n\n\n\n\npackages/staticsite/packaging\n\n\npackages/staticsite/spec\n\n\n\n\n\n\nInfo\n\n\n\n\nPackaging is where we write how to compile or build our software (our static website)\n\n\nSpec is where we define things that our static site will need to create the package, files etc..\n\n\n\n\n\n\nLets update the spec file first, it will tell the package what we need to build with.\n\n\n\n\nNote\n\n\nBOSH will look in the src directory first for any resources, if they aren't there, it will look in the blobstore.\n\n\n\n\nEarlier we downloaded a zip file, and created an index.html file. We need to tell our spec file these 2 files exist, and where to find them.\n\n\ncat \n \nEOF\n \n packages/staticsite/spec\n---\nname: staticsite\n\ndependencies: \n[]\n\n\nfiles:\n  - static/index.html\n  - static/bootstrap-4.1.3-dist.zip\nEOF\n\n\n\n\n\nGreat, now we need to tell BOSH how to package these 2 things together.\n\n\ncat \n \nEOF\n \n packages/staticsite/packaging\n\nset\n -e\n\n\necho\n \nMoving index.html to install target\n\ncp -a static/index.html \n${\nBOSH_INSTALL_TARGET\n}\n\n\n\necho\n \nExtract bootsrap resources into target\n\nunzip static/bootstrap-4.1.3-dist.zip -d \n${\nBOSH_INSTALL_TARGET\n}\n\nEOF\n\n\n\n\n\nSince the bootstrap ZIP file contains our css/js, we need to unzip it into the install target directory to actually be able to use it.\n\n\n\n\nNote\n\n\n${BOSH_INSTALL_TARGET}\n is a location that will be created on the deployed VM. In this case it will reference the final directory of \n/var/vcap/packages/staticsite/\n\n\n\n\nGreat, we have a script that tells BOSH how to put all our bits together. Now we need a job that knows what to do with our package.\n\n\nGenerate Job\n#\n\n\nNow we need to create a job that will tell BOSH how to use this package. Since it is a simple static website, our job will be relatively simple.\n\n\nFirst we need to create the job structure.\n\n\nbosh generate-job staticsite\n\n\n\n\n\nThis creates a few files\n\n\njobs/staticsite/spec\njobs/staticsite/monit\njobs/staticsite/templates/\n\n\n\n\n\n\n\nspec is a file that contains properties and package requirements for this job\n\n\nmonit should know how to start/stop any services this job may have\n\n\ntemplates is a place to store templates, like start and stop scripts, drain scripts, etc.\n\n\n\n\nNow we have the job skeleton, we need to tell it about our package.\n\n\nWe will need to set up a default docroot property, and tell it about a pre-start script we need.\n\n\ncat \n \nEOF\n \n jobs/staticsite/spec\n---\nname: staticsite\n\ntemplates:\n  pre-start.sh: bin/pre-start\n\npackages:\n  - staticsite\n\nproperties:\n  docroot:\n    description: Nginx docroot\n    default: /var/vcap/store/nginx/www/document_root\nEOF\n\n\n\n\n\nWe aren't going to use any services in this release or job, so leave the monit file blank.\n\n\nBut we do need to tell BOSH how to set up our site on the server, for this we need a pre-start script (which has already been defined in the spec file)\n\n\nThis contains some embedded ruby in it, which BOSH knows how to interpret.\n\n\ncat \n \nEOF\n \n jobs/staticsite/templates/pre-start.sh\n\n#!/bin/bash\n\n\necho\n \nCreate the docroot base directory\n\nmkdir -p \n$(\ndirname \n%\n=\n p\n(\ndocroot\n)\n %\n)\n\n\necho\n \nIf it our docroot already exists within it, delete it\n\n\nif\n \n[[\n -d \n%= p(\ndocroot\n) %\n \n]]\n\n\nthen\n\n  rm -rf \n%\n=\n p\n(\ndocroot\n)\n %\n\n\nfi\n\n\necho\n \nCopy our new docroot into the base directory\n\ncp -a /var/vcap/packages/staticsite \n%\n=\n p\n(\ndocroot\n)\n %\n\n\necho\n \nMake sure vcap owns it\n\nchown -R vcap:vcap \n%\n=\n p\n(\ndocroot\n)\n %\n\nEOF\n\n\n\n\n\nCreate Release\n#\n\n\nGreat, we have the skeleton for a release done, now we need to create a release archive in preparation for uploading it to our director.\n\n\nThis will create a release archive in \n/tmp/static-site.tgz\n.\n\n\nbosh create-release --force --tarball\n=\n/tmp/static-site.tgz\n\n\n\n\n\n\n\nInfo\n\n\nA release archive contains EVERYTHING needed to build the release, it will contain all sourcecode for your packages and scripts. This is part of the modern release engineering principles.\n\n\n\n\nNow upload the release to the director\n\n\nbosh upload-release /tmp/static-site.tgz", 
            "title": "Create BOSH Release"
        }, 
        {
            "location": "/release/#init_release", 
            "text": "First we need to create the release using the following command. It will create a directory called  staticsite-boshrelease  and will set up a few directories and files for us to help get started.  bosh init-release --dir = staticsite-boshrelease  This will create some directories  config/\njobs/\npackages/\nsrc/   config contains files that describe our release and where our release stores its blobs externally.  jobs contains all the jobs that this release will have available to it, a job is a way to run a package or packages  packages contains the packages that will be used in this release, it describes how to build/compile the packages  src is where you can store sourcecode and files if you don't want to utilise an external blobstore", 
            "title": "Init Release"
        }, 
        {
            "location": "/release/#create_sourceblob_files", 
            "text": "Now that we have our release skeleton, we need to create the HTML that will deployed in this release, and all the resources we are using in our HTML (css/js).  First we need to make a directory in the src folder to store our files that we need.  mkdir src/static  Now we need to get the bootstrap archive that contains the css/js we will be using and put it into the  src/static  directory too.  wget -O src/static/bootstrap-4.1.3-dist.zip https://github.com/twbs/bootstrap/releases/download/v4.1.3/bootstrap-4.1.3-dist.zip  And finally, generate the index.html file we will use.  cat    EOF    src/static/index.html html \n   head \n     title Samuel L Ipsum /title \n     link  rel = stylesheet   href = /css/bootstrap.min.css \n     script  src = /js/bootstrap.min.js /script \n   /head \n   body \n     nav  class = navbar navbar-expand-lg navbar-dark bg-dark \n       button  class = navbar-toggler   type = button  data-toggle = collapse  data-target = #navbarSupportedContent  aria-controls = navbarSupportedContent  aria-expanded = false  aria-label = Toggle navigation \n         span  class = navbar-toggler-icon /span \n       /button \n       div  class = collapse navbar-collapse   id = navbarSupportedContent \n         ul  class = navbar-nav mr-auto \n           li  class = nav-item active \n             a  class = nav-link   href = / Home  span  class = sr-only ( current ) /span /a \n           /li \n         /ul \n       /div \n     /nav \n     div  class = container \n       h1 Samuel L Ipsum /h1 \n       !-- start slipsum code -- \n       h2 Are you ready  for  the truth? /h2 \n      Well, the way they make shows is, they make one show. That show s called a pilot. Then they show that show to the people who make shows, and on the strength of that one show they decide if they re going to make more shows. Some pilots get picked and become television programs. Some don t, become nothing. She starred in one of the ones that became nothing.         h2 We happy? /h2        Now that we know who you are, I know who I am. I m not a mistake! It all makes sense! In a comic, you know how you can tell who the arch-villain s going to be? He s the exact opposite of the hero. And most  times  they re friends, like you and me! I should ve known way back when... You know why, David? Because of the kids. They called me Mr Glass.\n       !-- end slipsum code -- \n     /div \n   /body  /html \nEOF", 
            "title": "Create Source/Blob Files"
        }, 
        {
            "location": "/release/#generate_package", 
            "text": "Next up we need to create the package that will copy our static site into the right location on the deployed VM.  First generate the package skeleton for our package that we will call  staticsite  bosh generate-package staticsite  Now we have a skeleton directory, it contains 2 files   packages/staticsite/packaging  packages/staticsite/spec    Info   Packaging is where we write how to compile or build our software (our static website)  Spec is where we define things that our static site will need to create the package, files etc..    Lets update the spec file first, it will tell the package what we need to build with.   Note  BOSH will look in the src directory first for any resources, if they aren't there, it will look in the blobstore.   Earlier we downloaded a zip file, and created an index.html file. We need to tell our spec file these 2 files exist, and where to find them.  cat    EOF    packages/staticsite/spec\n---\nname: staticsite\n\ndependencies:  [] \n\nfiles:\n  - static/index.html\n  - static/bootstrap-4.1.3-dist.zip\nEOF  Great, now we need to tell BOSH how to package these 2 things together.  cat    EOF    packages/staticsite/packaging set  -e echo   Moving index.html to install target \ncp -a static/index.html  ${ BOSH_INSTALL_TARGET }  echo   Extract bootsrap resources into target \nunzip static/bootstrap-4.1.3-dist.zip -d  ${ BOSH_INSTALL_TARGET } \nEOF  Since the bootstrap ZIP file contains our css/js, we need to unzip it into the install target directory to actually be able to use it.   Note  ${BOSH_INSTALL_TARGET}  is a location that will be created on the deployed VM. In this case it will reference the final directory of  /var/vcap/packages/staticsite/   Great, we have a script that tells BOSH how to put all our bits together. Now we need a job that knows what to do with our package.", 
            "title": "Generate Package"
        }, 
        {
            "location": "/release/#generate_job", 
            "text": "Now we need to create a job that will tell BOSH how to use this package. Since it is a simple static website, our job will be relatively simple.  First we need to create the job structure.  bosh generate-job staticsite  This creates a few files  jobs/staticsite/spec\njobs/staticsite/monit\njobs/staticsite/templates/   spec is a file that contains properties and package requirements for this job  monit should know how to start/stop any services this job may have  templates is a place to store templates, like start and stop scripts, drain scripts, etc.   Now we have the job skeleton, we need to tell it about our package.  We will need to set up a default docroot property, and tell it about a pre-start script we need.  cat    EOF    jobs/staticsite/spec\n---\nname: staticsite\n\ntemplates:\n  pre-start.sh: bin/pre-start\n\npackages:\n  - staticsite\n\nproperties:\n  docroot:\n    description: Nginx docroot\n    default: /var/vcap/store/nginx/www/document_root\nEOF  We aren't going to use any services in this release or job, so leave the monit file blank.  But we do need to tell BOSH how to set up our site on the server, for this we need a pre-start script (which has already been defined in the spec file)  This contains some embedded ruby in it, which BOSH knows how to interpret.  cat    EOF    jobs/staticsite/templates/pre-start.sh #!/bin/bash  echo   Create the docroot base directory \nmkdir -p  $( dirname  % =  p ( docroot )  % )  echo   If it our docroot already exists within it, delete it  if   [[  -d  %= p( docroot ) %   ]]  then \n  rm -rf  % =  p ( docroot )  %  fi  echo   Copy our new docroot into the base directory \ncp -a /var/vcap/packages/staticsite  % =  p ( docroot )  %  echo   Make sure vcap owns it \nchown -R vcap:vcap  % =  p ( docroot )  % \nEOF", 
            "title": "Generate Job"
        }, 
        {
            "location": "/release/#create_release", 
            "text": "Great, we have the skeleton for a release done, now we need to create a release archive in preparation for uploading it to our director.  This will create a release archive in  /tmp/static-site.tgz .  bosh create-release --force --tarball = /tmp/static-site.tgz   Info  A release archive contains EVERYTHING needed to build the release, it will contain all sourcecode for your packages and scripts. This is part of the modern release engineering principles.   Now upload the release to the director  bosh upload-release /tmp/static-site.tgz", 
            "title": "Create Release"
        }, 
        {
            "location": "/deploy/", 
            "text": "Manifest\n#\n\n\nGreat, we are nearly done. We need to create a deployment manifest that tells BOSH how to deploy our release.\n\n\nCreate a manifest directory in our release, so we can keep everything there.\n\n\nmkdir manifests\n\n\n\n\n\nWe are also going to use an existing nginx BOSH release here too, so we need to make sure the manifest knows how to set it up too.\n\n\ncat \n \nEOF\n \n manifests/deployment.yml\n---\nname: static-web\n\nreleases:\n- name: staticsite-boshrelease\n  version: latest\n- name: nginx\n  version: latest\n\nstemcells:\n- alias: default\n  os: ubuntu-xenial\n  version: latest\n\ninstance_groups:\n- name: webserver\n  instances: \n1\n\n  stemcell: default\n  vm_type: default\n  azs: \n[\nz1\n]\n\n  persistent_disk_type: default\n  networks:\n  - name: default\n  jobs:\n  - name: staticsite\n    release: staticsite-boshrelease\n    properties:\n      docroot: \n((\nstaticsite_docroot\n))\n\n  - name: nginx\n    release: nginx\n    properties:\n      nginx_worker_processes: auto\n      nginx_worker_connections: \n1024\n\n      nginx_servers:\n      - server_name: \n((\nstaticsite_domain\n))\n\n        docroot: \n((\nstaticsite_docroot\n))\n\n        port: \n((\nstaticsite_http_port\n))\n\n        index: \nindex.html\n\n        access_log: /var/vcap/sys/log/nginx/access.log\n        error_log: /var/vcap/sys/log/nginx/error.log\n        custom_data: \n((\nnginx_config\n))\n\n\nupdate:\n  canaries: \n1\n\n  max_in_flight: \n1\n\n  serial: \nfalse\n\n  canary_watch_time: \n1000\n-60000\n  update_watch_time: \n1000\n-60000\nEOF\n\n\n\n\n\n\n\nNote\n\n\nIn our manifest, you will notice that a lot of things are defined as \ndefault\n. This allows our manifest to be as simple as possible, and we need to make sure our cloud manifest knows how to handle defaults.\n\n\n\n\nWe are also going to use some variables to set up the docroot, listening domain, and port for nginx. These are defined in the deployment manifest using \n((variable_name))\n.\n\n\ncat \n \nEOF\n \n manifests/variables.yml\nstaticsite_domain: staticsite.demo\nstaticsite_docroot: /var/vcap/store/nginx/www/document_root\nstaticsite_http_port: \n80\n\nnginx_config: \n|\n\n  location / \n{\n\n    try_files \n$uri\n \n$uri\n/ \n=\n404\n;\n\n  \n}\n\nEOF\n\n\n\n\n\nGreat, we are nearly there.\n\n\nStemcell\n#\n\n\nOur deployment calls for a stemcell called ubuntu-xenial. We should probably upload the stemcell into our director.\n\n\nbosh upload-stemcell https://bosh.io/d/stemcells/bosh-warden-boshlite-ubuntu-xenial-go_agent?v\n=\n97\n.17\n\n\n\n\n\n#already downloaded\n\nbosh upload-stemcell ~/Downloads/bosh-stemcell-97.17-warden-boshlite-ubuntu-xenial-go_agent.tgz\n\n\n\n\n\nThis can take some time, its about 400MB\n\n\nNginx Release\n#\n\n\nWe also told our deployment to use nginx. We should probably upload the nginx release too.\n\n\nbosh upload-release https://github.com/shreddedbacon/nginx-boshrelease/releases/download/v1.2.7/nginx-1.2.7.tgz\n\n\n\n\n\nCheck Director\n#\n\n\nCheck that our director has a stemcell associated to it\n\n\nbosh stemcells\n\n\n\n\n\nAnd also check that our 2 releases are there.\n\n\nbosh releases\n\n\n\n\n\nCloud Configuration\n#\n\n\nWe need to tell BOSH about our virtualbox \"cloud\" IaaS.\n\n\nLet's create the cloud configuration now.\n\n\ncat \n \nEOF\n \n virtualbox-cloud-config.yml\nazs:\n- name: z1\n\nvm_types:\n- name: default\n\ndisk_types:\n- name: default\n  disk_size: \n1024\n\n\nnetworks:\n- name: default\n  type: manual\n  subnets:\n  - azs: \n[\nz1\n]\n\n    dns: \n[\n8\n.8.8.8\n]\n\n    range: \n10\n.244.0.0/24\n    gateway: \n10\n.244.0.1\n    static: \n[\n10\n.244.0.34\n]\n\n    reserved: \n[]\n\n\ncompilation:\n  workers: \n5\n\n  az: z1\n  reuse_compilation_vms: \ntrue\n\n  vm_type: default\n  network: default\nEOF\n\n\n\n\n\n\n\nInfo\n\n\nThe cloud configuration describes our infrastructure. You will notice we have the following\n\n \ndefault\n vm_type, in our manifest, our vm to build is a default type.\n\n \ndefault\n disk_type, in our manifest this is what our \npersistent_disk_type\n refers to\n* \ndefault\n network, in our manifest, our instance group is associated to this default network\nSince our director is using virtualbox and warden cpi, there isn't much else we can describe.\n\n\n\n\nNow update the director so it know how to use our cloud.\n\n\nbosh update-cloud-config virtualbox-cloud-config.yml\n\n\n\n\n\nDeploying\n#\n\n\nNow it's time to actually deploy our release.\n\n\nbosh --deployment\n=\nstatic-web deploy manifests/deployment.yml --vars-file\n=\nmanifests/variables.yml\n\n\n\n\n\nor\n\n\nbosh -d static-web d manifests/deployment.yml -l manifests/variables.yml\n\n\n\n\n\nCheck Status\n#\n\n\nOnce the deployment is done, you can check the status of our VM and the services we are running on them.\n\n\nList Deployments\n#\n\n\nbosh deployments\n\n\n\n\n\nList VMs\n#\n\n\nbosh -d static-web vms\n\n\n\n\n\nList processes running on instances\n#\n\n\nbosh -d static-web instances --ps", 
            "title": "Deploy into VirtualBox"
        }, 
        {
            "location": "/deploy/#manifest", 
            "text": "Great, we are nearly done. We need to create a deployment manifest that tells BOSH how to deploy our release.  Create a manifest directory in our release, so we can keep everything there.  mkdir manifests  We are also going to use an existing nginx BOSH release here too, so we need to make sure the manifest knows how to set it up too.  cat    EOF    manifests/deployment.yml\n---\nname: static-web\n\nreleases:\n- name: staticsite-boshrelease\n  version: latest\n- name: nginx\n  version: latest\n\nstemcells:\n- alias: default\n  os: ubuntu-xenial\n  version: latest\n\ninstance_groups:\n- name: webserver\n  instances:  1 \n  stemcell: default\n  vm_type: default\n  azs:  [ z1 ] \n  persistent_disk_type: default\n  networks:\n  - name: default\n  jobs:\n  - name: staticsite\n    release: staticsite-boshrelease\n    properties:\n      docroot:  (( staticsite_docroot )) \n  - name: nginx\n    release: nginx\n    properties:\n      nginx_worker_processes: auto\n      nginx_worker_connections:  1024 \n      nginx_servers:\n      - server_name:  (( staticsite_domain )) \n        docroot:  (( staticsite_docroot )) \n        port:  (( staticsite_http_port )) \n        index:  index.html \n        access_log: /var/vcap/sys/log/nginx/access.log\n        error_log: /var/vcap/sys/log/nginx/error.log\n        custom_data:  (( nginx_config )) \n\nupdate:\n  canaries:  1 \n  max_in_flight:  1 \n  serial:  false \n  canary_watch_time:  1000 -60000\n  update_watch_time:  1000 -60000\nEOF   Note  In our manifest, you will notice that a lot of things are defined as  default . This allows our manifest to be as simple as possible, and we need to make sure our cloud manifest knows how to handle defaults.   We are also going to use some variables to set up the docroot, listening domain, and port for nginx. These are defined in the deployment manifest using  ((variable_name)) .  cat    EOF    manifests/variables.yml\nstaticsite_domain: staticsite.demo\nstaticsite_docroot: /var/vcap/store/nginx/www/document_root\nstaticsite_http_port:  80 \nnginx_config:  | \n  location /  { \n    try_files  $uri   $uri /  = 404 ; \n   } \nEOF  Great, we are nearly there.", 
            "title": "Manifest"
        }, 
        {
            "location": "/deploy/#stemcell", 
            "text": "Our deployment calls for a stemcell called ubuntu-xenial. We should probably upload the stemcell into our director.  bosh upload-stemcell https://bosh.io/d/stemcells/bosh-warden-boshlite-ubuntu-xenial-go_agent?v = 97 .17  #already downloaded \nbosh upload-stemcell ~/Downloads/bosh-stemcell-97.17-warden-boshlite-ubuntu-xenial-go_agent.tgz  This can take some time, its about 400MB", 
            "title": "Stemcell"
        }, 
        {
            "location": "/deploy/#nginx_release", 
            "text": "We also told our deployment to use nginx. We should probably upload the nginx release too.  bosh upload-release https://github.com/shreddedbacon/nginx-boshrelease/releases/download/v1.2.7/nginx-1.2.7.tgz", 
            "title": "Nginx Release"
        }, 
        {
            "location": "/deploy/#check_director", 
            "text": "Check that our director has a stemcell associated to it  bosh stemcells  And also check that our 2 releases are there.  bosh releases", 
            "title": "Check Director"
        }, 
        {
            "location": "/deploy/#cloud_configuration", 
            "text": "We need to tell BOSH about our virtualbox \"cloud\" IaaS.  Let's create the cloud configuration now.  cat    EOF    virtualbox-cloud-config.yml\nazs:\n- name: z1\n\nvm_types:\n- name: default\n\ndisk_types:\n- name: default\n  disk_size:  1024 \n\nnetworks:\n- name: default\n  type: manual\n  subnets:\n  - azs:  [ z1 ] \n    dns:  [ 8 .8.8.8 ] \n    range:  10 .244.0.0/24\n    gateway:  10 .244.0.1\n    static:  [ 10 .244.0.34 ] \n    reserved:  [] \n\ncompilation:\n  workers:  5 \n  az: z1\n  reuse_compilation_vms:  true \n  vm_type: default\n  network: default\nEOF   Info  The cloud configuration describes our infrastructure. You will notice we have the following   default  vm_type, in our manifest, our vm to build is a default type.   default  disk_type, in our manifest this is what our  persistent_disk_type  refers to\n*  default  network, in our manifest, our instance group is associated to this default network\nSince our director is using virtualbox and warden cpi, there isn't much else we can describe.   Now update the director so it know how to use our cloud.  bosh update-cloud-config virtualbox-cloud-config.yml", 
            "title": "Cloud Configuration"
        }, 
        {
            "location": "/deploy/#deploying", 
            "text": "Now it's time to actually deploy our release.  bosh --deployment = static-web deploy manifests/deployment.yml --vars-file = manifests/variables.yml  or  bosh -d static-web d manifests/deployment.yml -l manifests/variables.yml", 
            "title": "Deploying"
        }, 
        {
            "location": "/deploy/#check_status", 
            "text": "Once the deployment is done, you can check the status of our VM and the services we are running on them.", 
            "title": "Check Status"
        }, 
        {
            "location": "/deploy/#list_deployments", 
            "text": "bosh deployments", 
            "title": "List Deployments"
        }, 
        {
            "location": "/deploy/#list_vms", 
            "text": "bosh -d static-web vms", 
            "title": "List VMs"
        }, 
        {
            "location": "/deploy/#list_processes_running_on_instances", 
            "text": "bosh -d static-web instances --ps", 
            "title": "List processes running on instances"
        }, 
        {
            "location": "/openstack/", 
            "text": "Most of what is here is only used for this demo, some key places to look at are the following if you want to find out main differences.\n\n\n\n\nDeployment Manifest\n\n\nOperations Files\n\n\nCloud Configuration\n\n\n\n\nReference Information\n#\n\n\nThis section is for the demo only\n\n\nLoadBalancer\n#\n\n\n\n\n192.168.101.69\n\n\n\n\nSSH Tunnels\n#\n\n\nA lot of the networking in this section is specific to the demo performed at the Infracoders meetup, be aware it probably won't work elsewhere.\n\n\nssh -nNt -L 2222:192.168.101.91:22 10.8.0.10 #jumpbox\nssh -nNt -L 7000:192.168.101.30:80 10.8.0.10 #openstack dashboard\nssh -nNt -L 7001:192.168.101.69:80 10.8.0.10 #openstack loadbalancer\nssh -nNt -p 2222 -L 7002:192.168.209.7:8080 ubuntu@localhost #jumpbox-\ndirector-\nturbulence\n\n\n\n\n\nAccess\n#\n\n\nWeb\n#\n\n\n\n\nOpenstack Dashboard\n\n\nOpenstack Load Balancer Pool\n\n\nLoad Balancer\n\n\nTurbulence Dashboard\n\n\n\n\nJumpbox\n#\n\n\nIf using the created release, cp file to openstack jumpbox, otherwise use release from the the github repo \nhere\n\n\nscp -p 2222 /tmp/static-site.tgz ubuntu@localhost:/tmp/static-site.tgz\nssh -p ubuntu@localhost\n\n\n\n\n\nResources\n#\n\n\nDeployment Manifest\n#\n\n\nCreate the deployment manifest on the jumpbox, this is exactly the same manifest as used in virtualbox\n\n\ncd\nmkdir demo\ncat \n \nEOF\n \n demo/deployment.yml\n---\nname: static-web\n\nreleases:\n- name: staticsite-boshrelease\n  version: latest\n- name: nginx\n  version: latest\n\nstemcells:\n- alias: default\n  os: ubuntu-xenial\n  version: latest\n\ninstance_groups:\n- name: webserver\n  instances: 1\n  stemcell: default\n  vm_type: default\n  azs: [z1]\n  persistent_disk_type: default\n  networks:\n  - name: default\n  jobs:\n  - name: staticsite\n    release: staticsite-boshrelease\n    properties:\n      docroot: ((staticsite_docroot))\n  - name: nginx\n    release: nginx\n    properties:\n      nginx_worker_processes: auto\n      nginx_worker_connections: 1024\n      nginx_servers:\n      - server_name: ((staticsite_domain))\n        docroot: ((staticsite_docroot))\n        port: ((staticsite_http_port))\n        index: \nindex.html\n\n        access_log: /var/vcap/sys/log/nginx/access.log\n        error_log: /var/vcap/sys/log/nginx/error.log\n        custom_data: ((nginx_config))\n\nupdate:\n  canaries: 1\n  max_in_flight: 1\n  serial: false\n  canary_watch_time: 1000-60000\n  update_watch_time: 1000-60000\nEOF\n\n\n\n\n\nWe are also going to use some variables to set up the docroot and listening domain and port for nginx too these are defined in the deployment manifest using \n((variable_name))\n\n\ncat \n \nEOF\n \n demo/variables.yml\nstaticsite_domain: staticsite.demo\nstaticsite_docroot: /var/vcap/store/nginx/www/document_root\nstaticsite_http_port: 80\nnginx_config: |\n  location / {\n    try_files $uri $uri/ =404;\n  }\nEOF\n\n\n\n\n\nOperations Files\n#\n\n\nWe want to creat some operations that override the behaviour of our original default deployment.\n\n\ncat \n \nEOF\n \n demo/ops-instances.yml\n---\n- type: replace\n  path: /instance_groups/name=webserver/instances\n  value: 6\n- type: replace\n  path: /instance_groups/name=webserver/vm_type\n  value: lbmicro\n- type: replace\n  path: /instance_groups/name=webserver/networks/name=default/name\n  value: demonet01\nEOF\n\n\n\n\n\n\n\nInfo\n\n\nOur operations are only changing the vm_type and the number of instances we want to deploy, and which network they will live in. The vm_type \nlbmicro\n is defined in the Cloud Configuration.\n\n\n\n\nCloud Configuration\n#\n\n\ncat \n \nEOF\n \n demo/cloud-config.yml\n---\nazs:\n- name: z1\n  cloud_properties:\n    availability_zone: nova\n\nvm_types:\n- name: default\n  cloud_properties:\n    instance_type: m1.micro\n- name: tiny\n  cloud_properties:\n    instance_type: m1.tiny\n- name: micro\n  cloud_properties:\n    instance_type: m1.micro\n- name: small\n  cloud_properties:\n    instance_type: m1.small\n- name: medium\n  cloud_properties:\n    instance_type: m1.medium\n- name: large\n  cloud_properties:\n    instance_type: m1.large\n- name: xlarge\n  cloud_properties:\n    instance_type: m1.xlarge\n- name: lbsmall\n  cloud_properties:\n    instance_type: m1.small\n    loadbalancer_pools:\n      - name: demo-pool\n        port: 80\n- name: lbmicro\n  cloud_properties:\n    instance_type: m1.micro\n    loadbalancer_pools:\n      - name: demo-pool\n        port: 80\n\ndisk_types:\n- name: default\n  disk_size: 1024\n  cloud_properties:\n    type: nfs\n- name: micro\n  disk_size: 5_120\n  cloud_properties:\n    type: nfs\n- name: small\n  disk_size: 10_240\n  cloud_properties:\n    type: nfs\n- name: medium\n  disk_size: 20_480\n  cloud_properties:\n    type: nfs\n- name: large\n  disk_size: 30_720\n  cloud_properties:\n    type: nfs\n\nnetworks:\n- name: default\n  type: manual\n  subnets:\n  - azs: [z1]\n    dns: [192.168.101.1]\n    range: 192.168.209.0/24\n    gateway: 192.168.209.1\n    static: [192.168.209.10-192.168.209.99]\n    reserved: [192.168.209.2-192.168.209.9,192.168.209.100]\n    cloud_properties:\n      net_id: 16533825-c891-4e2b-8124-490a0b5bae4e\n      security_groups: [demo-bosh, demo-web, demo-all]\n- name: demonet01\n  type: manual\n  subnets:\n  - azs: [z1]\n    dns: [192.168.101.1]\n    range: 192.168.140.0/24\n    gateway: 192.168.140.1\n    static: [192.168.140.10-192.168.140.99]\n    reserved: [192.168.140.2-192.168.140.9,192.168.140.100]\n    cloud_properties:\n      net_id: ea119a90-86a0-44fc-b86c-3aa6c50dd3e0\n      security_groups: [demo-bosh, demo-web]\n- name: vip\n  type: vip\n\ncompilation:\n  workers: 4\n  az: z1\n  reuse_compilation_vms: true\n  vm_type: medium\n  network: default\nEOF\n\n\n\n\n\n\n\nInfo\n\n\nYou can see that we have cloud_properties defined for some things in this manifest, where our virtualbox cloud configuration doesn't.\nCloud properties are used to tell the CPI what to use when it builds, or what to attach something to.\nIn the case of \nlbmicro\n we are telling it that the instance_type to use in openstack is an m1.micro, and that once built they need to be assigned to the loadbalancer pool called \ndemo-pool\n.\n\n\nSimilar things are done for the network definition where it tells the CPI which networks to build in, and which security groups to assign to vms built in those networks.\n\n\n\n\nDeploying\n#\n\n\nNow we are ready to deploy it into openstack.\n\n\ncd bucc\n\n\n\n\n\nUpload our cloud configuration\n\n\nbosh ucc ../demo/cloud-config.yml\n\n\n\n\n\nUpload our releases\n\n\nbosh upload-stemcell https://bosh.io/d/stemcells/bosh-openstack-kvm-ubuntu-xenial-go_agent?v=97.17\n\n\n\n\n\nbosh upload-release https://github.com/shreddedbacon/nginx-boshrelease/releases/download/v1.2.7/nginx-1.2.7.tgz\n\n\n\n\n\nbosh upload-release /tmp/static-site.tgz\n# OR\nbosh upload-release https://github.com/shreddedbacon/staticsite-boshrelease/releases/download/v1.0.0/staticsite-boshrelease-v1.0.0.tgz\n\n\n\n\n\nAnd finally deploy it\n\n\n# no LB\nbosh -d static-web d ../demo/deployment.yml -l ../demo/variables.yml\n\n\n\n\n\n# with LB\nbosh -d static-web d ../demo/deployment.yml -o ../demo/ops-instances.yml -l ../demo/variables.yml", 
            "title": "Deploy into Openstack"
        }, 
        {
            "location": "/openstack/#reference_information", 
            "text": "This section is for the demo only", 
            "title": "Reference Information"
        }, 
        {
            "location": "/openstack/#loadbalancer", 
            "text": "192.168.101.69", 
            "title": "LoadBalancer"
        }, 
        {
            "location": "/openstack/#ssh_tunnels", 
            "text": "A lot of the networking in this section is specific to the demo performed at the Infracoders meetup, be aware it probably won't work elsewhere.  ssh -nNt -L 2222:192.168.101.91:22 10.8.0.10 #jumpbox\nssh -nNt -L 7000:192.168.101.30:80 10.8.0.10 #openstack dashboard\nssh -nNt -L 7001:192.168.101.69:80 10.8.0.10 #openstack loadbalancer\nssh -nNt -p 2222 -L 7002:192.168.209.7:8080 ubuntu@localhost #jumpbox- director- turbulence", 
            "title": "SSH Tunnels"
        }, 
        {
            "location": "/openstack/#access", 
            "text": "", 
            "title": "Access"
        }, 
        {
            "location": "/openstack/#web", 
            "text": "Openstack Dashboard  Openstack Load Balancer Pool  Load Balancer  Turbulence Dashboard", 
            "title": "Web"
        }, 
        {
            "location": "/openstack/#jumpbox", 
            "text": "If using the created release, cp file to openstack jumpbox, otherwise use release from the the github repo  here  scp -p 2222 /tmp/static-site.tgz ubuntu@localhost:/tmp/static-site.tgz\nssh -p ubuntu@localhost", 
            "title": "Jumpbox"
        }, 
        {
            "location": "/openstack/#resources", 
            "text": "", 
            "title": "Resources"
        }, 
        {
            "location": "/openstack/#deployment_manifest", 
            "text": "Create the deployment manifest on the jumpbox, this is exactly the same manifest as used in virtualbox  cd\nmkdir demo\ncat    EOF    demo/deployment.yml\n---\nname: static-web\n\nreleases:\n- name: staticsite-boshrelease\n  version: latest\n- name: nginx\n  version: latest\n\nstemcells:\n- alias: default\n  os: ubuntu-xenial\n  version: latest\n\ninstance_groups:\n- name: webserver\n  instances: 1\n  stemcell: default\n  vm_type: default\n  azs: [z1]\n  persistent_disk_type: default\n  networks:\n  - name: default\n  jobs:\n  - name: staticsite\n    release: staticsite-boshrelease\n    properties:\n      docroot: ((staticsite_docroot))\n  - name: nginx\n    release: nginx\n    properties:\n      nginx_worker_processes: auto\n      nginx_worker_connections: 1024\n      nginx_servers:\n      - server_name: ((staticsite_domain))\n        docroot: ((staticsite_docroot))\n        port: ((staticsite_http_port))\n        index:  index.html \n        access_log: /var/vcap/sys/log/nginx/access.log\n        error_log: /var/vcap/sys/log/nginx/error.log\n        custom_data: ((nginx_config))\n\nupdate:\n  canaries: 1\n  max_in_flight: 1\n  serial: false\n  canary_watch_time: 1000-60000\n  update_watch_time: 1000-60000\nEOF  We are also going to use some variables to set up the docroot and listening domain and port for nginx too these are defined in the deployment manifest using  ((variable_name))  cat    EOF    demo/variables.yml\nstaticsite_domain: staticsite.demo\nstaticsite_docroot: /var/vcap/store/nginx/www/document_root\nstaticsite_http_port: 80\nnginx_config: |\n  location / {\n    try_files $uri $uri/ =404;\n  }\nEOF", 
            "title": "Deployment Manifest"
        }, 
        {
            "location": "/openstack/#operations_files", 
            "text": "We want to creat some operations that override the behaviour of our original default deployment.  cat    EOF    demo/ops-instances.yml\n---\n- type: replace\n  path: /instance_groups/name=webserver/instances\n  value: 6\n- type: replace\n  path: /instance_groups/name=webserver/vm_type\n  value: lbmicro\n- type: replace\n  path: /instance_groups/name=webserver/networks/name=default/name\n  value: demonet01\nEOF   Info  Our operations are only changing the vm_type and the number of instances we want to deploy, and which network they will live in. The vm_type  lbmicro  is defined in the Cloud Configuration.", 
            "title": "Operations Files"
        }, 
        {
            "location": "/openstack/#cloud_configuration", 
            "text": "cat    EOF    demo/cloud-config.yml\n---\nazs:\n- name: z1\n  cloud_properties:\n    availability_zone: nova\n\nvm_types:\n- name: default\n  cloud_properties:\n    instance_type: m1.micro\n- name: tiny\n  cloud_properties:\n    instance_type: m1.tiny\n- name: micro\n  cloud_properties:\n    instance_type: m1.micro\n- name: small\n  cloud_properties:\n    instance_type: m1.small\n- name: medium\n  cloud_properties:\n    instance_type: m1.medium\n- name: large\n  cloud_properties:\n    instance_type: m1.large\n- name: xlarge\n  cloud_properties:\n    instance_type: m1.xlarge\n- name: lbsmall\n  cloud_properties:\n    instance_type: m1.small\n    loadbalancer_pools:\n      - name: demo-pool\n        port: 80\n- name: lbmicro\n  cloud_properties:\n    instance_type: m1.micro\n    loadbalancer_pools:\n      - name: demo-pool\n        port: 80\n\ndisk_types:\n- name: default\n  disk_size: 1024\n  cloud_properties:\n    type: nfs\n- name: micro\n  disk_size: 5_120\n  cloud_properties:\n    type: nfs\n- name: small\n  disk_size: 10_240\n  cloud_properties:\n    type: nfs\n- name: medium\n  disk_size: 20_480\n  cloud_properties:\n    type: nfs\n- name: large\n  disk_size: 30_720\n  cloud_properties:\n    type: nfs\n\nnetworks:\n- name: default\n  type: manual\n  subnets:\n  - azs: [z1]\n    dns: [192.168.101.1]\n    range: 192.168.209.0/24\n    gateway: 192.168.209.1\n    static: [192.168.209.10-192.168.209.99]\n    reserved: [192.168.209.2-192.168.209.9,192.168.209.100]\n    cloud_properties:\n      net_id: 16533825-c891-4e2b-8124-490a0b5bae4e\n      security_groups: [demo-bosh, demo-web, demo-all]\n- name: demonet01\n  type: manual\n  subnets:\n  - azs: [z1]\n    dns: [192.168.101.1]\n    range: 192.168.140.0/24\n    gateway: 192.168.140.1\n    static: [192.168.140.10-192.168.140.99]\n    reserved: [192.168.140.2-192.168.140.9,192.168.140.100]\n    cloud_properties:\n      net_id: ea119a90-86a0-44fc-b86c-3aa6c50dd3e0\n      security_groups: [demo-bosh, demo-web]\n- name: vip\n  type: vip\n\ncompilation:\n  workers: 4\n  az: z1\n  reuse_compilation_vms: true\n  vm_type: medium\n  network: default\nEOF   Info  You can see that we have cloud_properties defined for some things in this manifest, where our virtualbox cloud configuration doesn't.\nCloud properties are used to tell the CPI what to use when it builds, or what to attach something to.\nIn the case of  lbmicro  we are telling it that the instance_type to use in openstack is an m1.micro, and that once built they need to be assigned to the loadbalancer pool called  demo-pool .  Similar things are done for the network definition where it tells the CPI which networks to build in, and which security groups to assign to vms built in those networks.", 
            "title": "Cloud Configuration"
        }, 
        {
            "location": "/openstack/#deploying", 
            "text": "Now we are ready to deploy it into openstack.  cd bucc  Upload our cloud configuration  bosh ucc ../demo/cloud-config.yml  Upload our releases  bosh upload-stemcell https://bosh.io/d/stemcells/bosh-openstack-kvm-ubuntu-xenial-go_agent?v=97.17  bosh upload-release https://github.com/shreddedbacon/nginx-boshrelease/releases/download/v1.2.7/nginx-1.2.7.tgz  bosh upload-release /tmp/static-site.tgz\n# OR\nbosh upload-release https://github.com/shreddedbacon/staticsite-boshrelease/releases/download/v1.0.0/staticsite-boshrelease-v1.0.0.tgz  And finally deploy it  # no LB\nbosh -d static-web d ../demo/deployment.yml -l ../demo/variables.yml  # with LB\nbosh -d static-web d ../demo/deployment.yml -o ../demo/ops-instances.yml -l ../demo/variables.yml", 
            "title": "Deploying"
        }, 
        {
            "location": "/turbulence/", 
            "text": "We can also run some chaos engineering if your director has been deployed with turbulence.\n\n\n\n\nTurbulence API\n\n\nTurbulence API Docs\n\n\n\n\n\n\nNote\n\n\nBy default BUCC does not build with turbulence\n\n\ncp src/bosh-deployment/turbulence.yml ops/9-turbulence.yml\n\n\n\n\nexport\n \nTURBULENCE_PASSWORD\n=\n$\n(\nbosh\n \nint\n \nstate\n/\ncreds\n.\nyml\n \n--\npath\n \n/\nturbulence_api_password\n)\n\n\ncat\n \n \nEOF\n \n \nkill\n.\nsh\n\n\nset\n \n-\ne\n\n\n\nbody\n=\n\n\n{\n\n    \nTasks\n:\n \n[{\n\n        \nType\n:\n \nKill\n\n    \n}],\n\n\n    \nSelector\n:\n \n{\n\n        \nDeployment\n:\n \n{\n\n            \nName\n:\n \nstatic-web\n\n        \n},\n\n        \nGroup\n:\n \n{\n\n            \nName\n:\n \nwebserver\n\n        \n},\n\n        \nID\n:\n \n{\n\n            \nLimit\n:\n \n10%-60%\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\necho\n \n$\nbody\n \n|\n \ncurl\n \n-\nvvv\n \n-\nk\n \n-\nX\n \nPOST\n \nhttps\n:\n//turbulence:${TURBULENCE_PASSWORD}@192.168.209.7:8080/api/v1/incidents -H \nAccept: application/json\n -d @-\n\n\necho\n\n\nEOF\n\n\nchmod\n \n+\nx\n \nkill\n.\nsh\n\n\n\n\n\n\nRun it\n\n\n./kill.sh\n\n\n\n\n\nChecking in the Openstack console, you will see that one or more vms will be gone.\n\n\nAfter about a minute or so, BOSH will see this machine missing and start the process of rebuilding it. You can also schedule instances to be destroyed, and a bunch of other chaos engineering tasks, like full disk, high cpu, high memory etc..", 
            "title": "Chaos Engineering"
        }
    ]
}